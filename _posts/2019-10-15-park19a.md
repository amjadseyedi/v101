---
title: Regularizing Neural Networks via Stochastic Branch Layers
crossref: acml19
abstract: We introduce a novel stochastic regularization technique for deep neural
  networks, which decomposes a layer into multiple branches with different parameters
  and merges stochastically sampled combinations of the outputs from the branches
  during training. Since the factorized branches can collapse into a single branch
  through a linear operation, inference requires no additional complexity compared
  to the ordinary layers. The proposed regularization method, referred to as StochasticBranch,
  is applicable to any linear layers such as fully-connected or convolution layers.
  The proposed regularizer allows the model to explore diverse regions of the model
  parameter space via multiple combinations of branches to find better local minima.
  An extensive set of experiments shows that our method effectively regularizes networks
  and further improves the generalization performance when used together with other
  existing regularization techniques.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: park19a
month: 0
tex_title: Regularizing Neural Networks via Stochastic Branch Layers
firstpage: 678
lastpage: 693
page: 678-693
order: 678
cycles: false
bibtex_author: Park, Wonpyo and Seo, Paul Hongsuck and Han, Bohyung and Cho, Minsu
author:
- given: Wonpyo
  family: Park
- given: Paul Hongsuck
  family: Seo
- given: Bohyung
  family: Han
- given: Minsu
  family: Cho
date: 2019-10-15
address: 
publisher: PMLR
container-title: Proceedings of The Eleventh Asian Conference on Machine Learning
volume: '101'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 10
  - 15
pdf: http://proceedings.mlr.press/v101/park19a/park19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
