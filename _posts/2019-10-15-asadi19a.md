---
title: Model-Based Reinforcement Learning Exploiting State-Action Equivalence
crossref: acml19
abstract: Leveraging an equivalence property in the state-space of a Markov Decision
  Process (MDP) has been investigated in several studies. This paper studies equivalence
  structure in the reinforcement learning (RL) setup, where transition distributions
  are no longer assumed to be known. We present a notion of similarity between transition
  probabilities of various state-action pairs of an MDP, which naturally defines an
  equivalence structure in the state-action space. We present equivalence-aware confidence
  sets for the case where the learner knows the underlying structure in advance. These
  sets are provably smaller than their corresponding equivalence-oblivious counterparts.
  In the more challenging case of an unknown equivalence structure, we present an
  algorithm called ApproxEquivalence that seeks to find an (approximate) equivalence
  structure, and define confidence sets using the approximate equivalence. To illustrate
  the efficacy of the presented confidence sets, we present C-UCRL, as a natural modification
  of UCRL2 for RL in undiscounted MDPs. In the case of a known equivalence structure,
  we show that C-UCRL improves over UCRL2 in terms of \emph{regret} by a factor of
  $\sqrt{SA/C}$, in any communicating MDP with $S$ states, $A$ actions, and $C$ classes,
  which corresponds to a massive improvement when $C\ll SA$. To the best of our knowledge,
  this is the first work providing regret bounds for RL when an equivalence structure
  in the MDP is efficiently exploited. In the case of an unknown equivalence structure,
  we show through numerical experiments that C-UCRL combined with ApproxEquivalence
  outperforms UCRL2 in ergodic MDPs.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: asadi19a
month: 0
tex_title: Model-Based Reinforcement Learning Exploiting State-Action Equivalence
firstpage: 204
lastpage: 219
page: 204-219
order: 204
cycles: false
bibtex_author: Asadi, Mahsa and Talebi, Mohammad Sadegh and Bourel, Hippolyte and
  Maillard, Odalric-Ambrym
author:
- given: Mahsa
  family: Asadi
- given: Mohammad Sadegh
  family: Talebi
- given: Hippolyte
  family: Bourel
- given: Odalric-Ambrym
  family: Maillard
date: 2019-10-15
address: 
publisher: PMLR
container-title: Proceedings of The Eleventh Asian Conference on Machine Learning
volume: '101'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 10
  - 15
pdf: http://proceedings.mlr.press/v101/asadi19a/asadi19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v101/asadi19a/asadi19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
